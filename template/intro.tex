
% The \section{} command formats and sets the title of this
% section. We'll deal with labels later.
\section{Introduction}
\label{sec:intro}

Genetic programming, inspired by Darwinian evolution, uses the principles of natural selection, mutation, and reproduction, to explore a problem space. In this case, we use GP to perform Symbolic Regression and find the function used to generate a dataset. Symbolic Regression, a generalization of Linear Regression, is the process of finding an equation of best fit for an arbitrary dataset. While Linear Regression yields a linear formula, Symbolic Regression can be applied to find any function of any number of variables. The genetic programming approach is often thought of as a double-edged sword. On one hand, it can be adapted to solve almost any type of problem. On the other hand, it is a fairly uninformed solution method. It uses relatively little information about the problem to solve it, relying instead on guided randomness to deliver a suitable result. This randomness means the path taken to arrive at the solution is hidden to the user. GP may give a supremely accurate result, but yields no insight into why that result works, raising an important question: If you have the answer without knowing why it's right, have you really learned anything? \\
In the case of Symbolic Regression, how we arrive at a solution or why we chose certain steps is not as important as the function we produce. According to Koza, GP lends itself well to Symbolic Regression because it is error-driven learning \cite{Koza97geneticprogramming}.  It also finds unorthodox ways of discovering mathematical identities, which allows the use of a very limited set of operations to generate a wide range of functions.
In the following sections, we will discuss how we handled problems of diversity and overfitting, our results from SR with GP, and what we can conclude from our data.
. \\



